ğŸ“„ RAG Chatbot (Advanced & Free)

A Retrieval-Augmented Generation (RAG) chatbot that answers questions from your documents using hybrid retrieval, reranking, and a local LLM â€” completely free, offline, and no API keys required.



ğŸš€ Features

ğŸ“‚ Multi-format document ingestion (PDF, TXT, CSV, DOC, MD, HTML)

ğŸ“¤ Drag-and-drop document upload via modern React UI

ğŸ§  Semantic search using embeddings

ğŸ” Hybrid retrieval (ChromaDB + BM25)

ğŸ¯ Reranking using cross-encoder models

ğŸ¤– Local LLM inference using Ollama (phi3:mini)

âš¡ Optimized for speed with caching & conditional execution

ğŸŒ FastAPI backend with full CRUD API

ğŸ¨ Modern React frontend with Tailwind CSS

ğŸŒ“ Light/Dark mode support

ğŸ“± Fully responsive design

ğŸ’¬ Chat-style interface with Markdown rendering

ğŸ” No paid APIs, runs fully locally







ğŸ—ï¸ Project Architecture

User (React Frontend)
 â†“
FastAPI Backend
 â”œâ”€â”€ /upload (Document Upload)
 â”œâ”€â”€ /documents (List/Delete)
 â””â”€â”€ /ask (Query RAG System)
      â†“
Query Expansion (optional)
 â†“
Hybrid Retrieval (BM25 + ChromaDB)
 â†“
Reranking (Cross-Encoder)
 â†“
Local LLM (Ollama - phi3:mini)
 â†“
Final Answer (with Sources)




ğŸ“ Folder Structure
RAG_CHATBOT/
â”œâ”€â”€ api.py                      # FastAPI backend with CRUD endpoints
â”œâ”€â”€ ui.py                       # Legacy Streamlit UI (optional)
â”œâ”€â”€ ingest.py                   # Document ingestion & embedding
â”œâ”€â”€ rag_chain.py                # Core RAG pipeline (optimized)
â”‚
â”œâ”€â”€ app/frontend/               # Modern React Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/         # React components
â”‚   â”‚   â”œâ”€â”€ services/           # API integration
â”‚   â”‚   â”œâ”€â”€ utils/              # Helper functions
â”‚   â”‚   â””â”€â”€ App.jsx             # Main app
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ local_llm.py            # Ollama LLM loader (cached)
â”‚
â”œâ”€â”€ pipelines/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ query_expansion.py      # Smart query expansion
â”‚
â”œâ”€â”€ retrievers/
â”‚   â”œâ”€â”€ hybrid.py               # BM25 + ChromaDB retrieval
â”‚   â”œâ”€â”€ reranker.py             # Cross-encoder reranking
â”‚   â”œâ”€â”€ vector.py               # Vector store retriever
â”‚   â””â”€â”€ bm25.py                 # BM25 retriever
â”‚
â”œâ”€â”€ data/docs/                  # Uploaded documents
â”œâ”€â”€ embeddings/chroma/          # ChromaDB vector store
â”œâ”€â”€ evaluation/                 # RAG evaluation metrics
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md






ğŸ§  How It Works (Simple Explanation)

Documents are ingested

PDFs are split into chunks

Chunks are converted into embeddings

Stored in FAISS vector database

User asks a question

Short queries may be expanded

Hybrid retrieval fetches relevant chunks

Reranker selects best chunks

LLM generates final answer using retrieved context

Optimizations

Models are loaded once

Reranking & expansion are used conditionally

Context size is limited for faster inference





ğŸ› ï¸ Installation & Setup


1ï¸âƒ£ Clone the repository
git clone https://github.com/your-username/RAG_CHATBOT.git
cd RAG_CHATBOT



2ï¸âƒ£ Create & activate virtual environment
python -m venv .venv
.venv\Scripts\activate   # Windows


3ï¸âƒ£ Install dependencies
pip install -r requirements.txt



4ï¸âƒ£ Install & run Ollama
ollama pull llama3
ollama run llama3


ğŸ“¥ Ingest Documents

Place your PDFs inside the data/ folder, then run:
python ingest.py



â–¶ï¸ Run the Application

Option 1: Modern React Frontend (Recommended)

Terminal 1 â€” Backend
uvicorn api:app --reload

Terminal 2 â€” Frontend
cd app/frontend
npm install  # First time only
npm run dev

Open http://localhost:3000 in your browser

Option 2: Legacy Streamlit UI

Terminal 1 â€” Backend
uvicorn api:app --reload

Terminal 2 â€” Frontend
streamlit run ui.py


ğŸ¨ Frontend Features

Modern React UI with:
- Drag-and-drop document upload
- Real-time document management
- Chat-style interface
- Markdown rendering for AI responses
- Collapsible source context
- Light/Dark mode toggle
- Fully responsive design
- Smooth animations

Backend API Endpoints:
- GET /ask?q=<query> - Ask questions
- POST /upload - Upload documents
- GET /documents - List all documents
- DELETE /documents/<filename> - Delete document


ğŸ“– Detailed Documentation

Frontend Guide: See app/frontend/README.md for detailed frontend documentation
Backend API: Visit http://localhost:8000/docs for interactive API documentation
